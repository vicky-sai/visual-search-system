# Vicky Visual Search

Vicky Visual Search is an enterprise-grade, fully containerized visual search system that enables users to locate relevant images based on natural language queries. It provides AI-driven, multimodal explanations for each search result, detailing *why* an image is relevant by analyzing its visual content.

The entire application stack (Frontend, Backend, Vector Database, and AI Model Server) is orchestrated with Docker Compose, featuring a **fully automated setup process**.

![Vicky Visual Search UI Screenshot](https://i.imgur.com/xO7vJdE.png)

---

## Key Features

*   **Natural Language Search:** Find images by describing what you're looking for (e.g., "a person hiking on a mountain at sunset").
*   **Multimodal AI Explanations:** Each search result is accompanied by a unique explanation generated by a vision-language model (`gemma3:4b`) that analyzes the image's specific content in relation to the query.
*   **Relevance Scoring:** Results are ranked and displayed with a percentage match score, providing clear insight into search relevance.
*   **Interactive Progress:** The user interface displays a real-time progress bar during the search, showing the steps from query analysis to explanation generation.
*   **Fully Automated Setup:** Docker Compose handles the entire setup, including pulling the required AI models, downloading the dataset, and generating embeddings.
*   **Scalable & Production-Ready:** The system is built with a modern, microservices-based architecture using FastAPI and React, ready for cloud deployment.

---

## Tech Stack

| Area      | Technology                                                                                                  |
| :-------- | :---------------------------------------------------------------------------------------------------------- |
| **Backend & AI** | Python, FastAPI, CLIP (`sentence-transformers`), ChromaDB (Vector DB), Ollama, `gemma3:4b` (Multimodal LLM) |
| **Frontend**     | React (with Vite), Axios                                                                                    |
| **DevOps**       | Docker, Docker Compose, Nginx, Bash Scripting                                                               |

---

## Prerequisites

To run this project, you will need:
*   **Docker** and **Docker Compose** installed and running on your machine. [Docker Desktop](https://www.docker.com/products/docker-desktop/) is the easiest way to get started.
*   A machine with sufficient RAM allocated to Docker. **A minimum of 8GB is recommended** to run the AI models smoothly.

---

## Quickstart Guide

The entire application, including data initialization and AI model downloads, is managed by Docker Compose.

### Step 1: Clone the Repository

```bash
git clone https://github.com/vicky-sai/visual-search-system.git
cd visual-search-system
```

### Step 2: Build and Run the Application

This single command will build the application images, start all services, and automatically run the one-time setup job in the background.

```bash
docker-compose up --build -d
```
*The `-d` flag runs the containers in detached (background) mode.*

### Step 3: Monitor the One-Time Setup (Optional, but Recommended)

The first time you run this, a special service (`init-backend`) will run in the background to download the AI model and prepare the image data. This can take **5-15 minutes**.

To watch the live progress, open a **new terminal window** and run:

```bash
docker-compose logs -f init-backend
```

This command will stream the logs from the initialization service. You will see the progress of the AI model download, image download, and embedding generation. Once the log shows **"VICKY VISUAL SEARCH INITIALIZATION COMPLETE"**, the setup is finished, and the main backend server will start automatically.

You can then press `Ctrl+C` to exit the log stream.

### Step 4: Use the Application

Once the initialization is complete, the system is fully operational.
*   **Frontend User Interface:** Open your browser to [**http://localhost:5173**](http://localhost:5173)
*   **Backend API Docs:** The API is available at [**http://localhost:8000/docs**](http://localhost:8000/docs)

*(Note: On subsequent startups, the initialization service will see that the data and models already exist and will finish in seconds.)*

---

## How to Stop the Application

To stop all running containers, run the following command from the project's root directory:

```bash
docker-compose down```
*This will stop and remove the containers, but your downloaded models and image data will be preserved in Docker volumes for the next startup.*

---

## Configuration

The project is easily configurable via the `docker-compose.yml` file. You can change key parameters in the `x-common-environment-vars` section at the top of the file without touching any source code.

| Variable                 | Default Value     | Description                                                          |
| :----------------------- | :---------------- | :------------------------------------------------------------------- |
| `OLLAMA_MODEL`           | `gemma3:4b`       | The multimodal Ollama model to use for generating explanations.      |
| `CLIP_MODEL_NAME`        | `clip-ViT-B-32`   | The CLIP model from Hugging Face used for generating embeddings.       |
| `NUM_IMAGES_TO_DOWNLOAD` | `500`             | The number of images to download for the dataset. Set to `25000` for the full set. |

After changing any of these values, simply run `docker-compose up --build -d` again to restart the application with the new settings.